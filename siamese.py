# -*- coding: utf-8 -*-
"""siamese_ml_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u313uNcofL4K0OWOfItgilkr9H4fnFt-
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import cv2
import numpy as np
import random
from tqdm import tqdm
import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# --- Step 0: Custom L1 Distance Layer ---
@tf.keras.utils.register_keras_serializable()
class L1DistanceLayer(tf.keras.layers.Layer):
    def call(self, inputs):
        x, y = inputs
        return tf.abs(x - y)

# --- Step 1: Load and Preprocess Dataset ---
def load_images_from_folder(folder, size=(100, 100)):
    images = []
    for filename in os.listdir(folder):
        img_path = os.path.join(folder, filename)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        if img is not None:
            img = cv2.resize(img, size)
            images.append(img)
    return images

def create_pairs(dataset_path):
    users = os.listdir(dataset_path)
    pairs = []
    labels = []

    for user in tqdm(users, desc="Generating image pairs"):
        user_path = os.path.join(dataset_path, user)
        images = load_images_from_folder(user_path)
        if len(images) < 2:
            continue

        for i in range(len(images) - 1):
            pairs.append([images[i], images[i + 1]])
            labels.append(1)

        neg_user = random.choice([u for u in users if u != user])
        neg_user_path = os.path.join(dataset_path, neg_user)
        neg_images = load_images_from_folder(neg_user_path)
        if neg_images:
            neg_img = random.choice(neg_images)
            pairs.append([images[0], neg_img])
            labels.append(0)

    X1 = np.array([p[0] for p in pairs]) / 255.0
    X2 = np.array([p[1] for p in pairs]) / 255.0
    y = np.array(labels)

    X1 = X1.reshape(-1, 100, 100, 1)
    X2 = X2.reshape(-1, 100, 100, 1)
    return X1, X2, y

#--- Step 2: Build Siamese Model ---
def build_embedding(input_shape=(100, 100, 1)):
    inputs = layers.Input(input_shape)
    x = layers.Conv2D(32, (7,7), activation='relu', padding='same')(inputs)
    x = layers.MaxPooling2D()(x)
    x = layers.Conv2D(64, (5,5), activation='relu', padding='same')(x)
    x = layers.MaxPooling2D()(x)
    x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)
    x = layers.Flatten()(x)
    x = layers.Dense(512, activation='sigmoid')(x)
    return Model(inputs, x, name="embedding")

def build_siamese_model(input_shape=(100, 100, 1)):
    embedding = build_embedding(input_shape)
    input_a = layers.Input(input_shape)
    input_b = layers.Input(input_shape)
    emb_a = embedding(input_a)
    emb_b = embedding(input_b)
    L1_distance = L1DistanceLayer(name="l1_distance_layer")([emb_a, emb_b])
    output = layers.Dense(1, activation='sigmoid')(L1_distance)
    return Model([input_a, input_b], output)

# --- Step 3: Train Model ---
def train_siamese_model(dataset_path):
    print("ðŸ”„ Preparing data...")
    X1, X2, y = create_pairs(dataset_path)
    print(f"âœ… Total pairs: {len(y)} (Positive: {sum(y)}, Negative: {len(y)-sum(y)})")

    X1_train, X1_test, X2_train, X2_test, y_train, y_test = train_test_split(X1, X2, y, test_size=0.25, random_state=42)
    print(f"ðŸ“Š Training samples: {len(y_train)}, Testing samples: {len(y_test)}")

    print("ðŸ§  Building model...")
    model = build_siamese_model((100, 100, 1))
    model.summary()

    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.00005), metrics=['accuracy'])

    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6
    , min_delta=0.001, restore_best_weights=True)

    print("ðŸ‹ï¸ Training model...")
    history = model.fit(
        [X1_train, X2_train], y_train,
        validation_data=([X1_test, X2_test], y_test),
        epochs=30, batch_size=16,
        callbacks=[early_stop], verbose=1
    )

    model_path = "/content/drive/MyDrive/smart_locker/siamese_model.h5"
    model.save(model_path)
    print(f"âœ… Model saved to {model_path}")

    # ðŸ“ˆ Plot training history
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title('Loss Over Epochs')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Val Accuracy')
    plt.title('Accuracy Over Epochs')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout()
    plt.show()

    return model_path, X1_test, X2_test, y_test, history

# --- Step 4: Test Prediction ---
def test_prediction(model_path, img1_path, img2_path, threshold=0.5):
    def preprocess(img_path):
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (100, 100))
        img = img / 255.0
        return img.reshape(1, 100, 100, 1)

    print("ðŸ” Loading model...")
    model = tf.keras.models.load_model(model_path, custom_objects={"L1DistanceLayer": L1DistanceLayer})

    img1 = preprocess(img1_path)
    img2 = preprocess(img2_path)

    prediction = model.predict([img1, img2])[0][0]
    print(f"ðŸ”Ž Similarity score: {prediction:.4f}")

    if prediction >= threshold:
        print("âœ… Prediction: SAME person")
    else:
        print("âŒ Prediction: DIFFERENT persons")

import matplotlib.pyplot as plt
import numpy as np


# from previous cells, we know dataset_path = "/content/drive/MyDrive/Smart_Locker_Dataset"

dataset_path = "/content/drive/MyDrive/Smart_Locker_Dataset"

# Create pairs to get the labels
# We don't need the image data (X1, X2) for just the distribution,
# but the create_pairs function returns them, so we'll capture them.
print("ðŸ”„ Preparing data to plot distribution...")
_, _, y = create_pairs(dataset_path)
print(f"âœ… Total pairs: {len(y)} (Positive: {sum(y)}, Negative: {len(y)-sum(y)})")

# Plot the distribution
labels, counts = np.unique(y, return_counts=True)
plt.figure(figsize=(6, 4))
plt.bar(["Different (0)", "Same (1)"], counts, color=['skyblue', 'lightcoral'])
plt.title('Distribution of Image Pairs (Same vs Different)')
plt.xlabel('Pair Type')
plt.ylabel('Count')
plt.show()

# --- Step 5: Confusion Matrix Evaluation ---
def evaluate_model_confusion_matrix(model_path, X1_test, X2_test, y_test, threshold=0.5):
    print("ðŸ” Loading model for evaluation...")
    model = tf.keras.models.load_model(model_path, custom_objects={"L1DistanceLayer": L1DistanceLayer})

    print("ðŸ”¢ Predicting on test data...")
    y_pred_probs = model.predict([X1_test, X2_test])
    y_pred = (y_pred_probs >= threshold).astype(int)

    print("ðŸ“‰ Generating confusion matrix...")
    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Different", "Same"])
    disp.plot(cmap=plt.cm.Blues)
    plt.title("Confusion Matrix")
    plt.show()

# --- MAIN ---
if __name__ == '__main__':
    dataset_path = "/content/drive/MyDrive/Smart_Locker_Dataset"
    model_path, X1_test, X2_test, y_test, history = train_siamese_model(dataset_path)

    test_prediction(
        model_path="/content/drive/MyDrive/siamese_model.h5",
        img1_path="/content/drive/MyDrive/Smart_Locker_Dataset/user1/test1.jpg",
        img2_path="/content/drive/MyDrive/Smart_Locker_Dataset/user1/train1.jpg"
    )

    evaluate_model_confusion_matrix(
        model_path=model_path,
        X1_test=X1_test,
        X2_test=X2_test,
        y_test=y_test
    )

# Print final training and testing accuracy
final_train_acc = history.history['accuracy'][-1]
final_val_acc = history.history['val_accuracy'][-1]

print(f"âœ… Final Training Accuracy: {final_train_acc * 100:.2f}%")
print(f"âœ… Final Validation Accuracy: {final_val_acc * 100:.2f}%")

test_prediction(
    model_path="/content/drive/MyDrive/siamese_model.h5",
    img1_path="/content/drive/MyDrive/Smart_Locker_Dataset/user3/test3.jpg",
    img2_path="/content/drive/MyDrive/Smart_Locker_Dataset/user2/train2.jpg"
)
